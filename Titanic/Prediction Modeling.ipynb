{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.preprocessing\n",
    "import sklearn.linear_model\n",
    "import sklearn.neighbors\n",
    "import sklearn.svm\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import wrangle #Custom scripts I created. See documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C', 'A', 'F', 'G', 'T', 'E', 'B', 'D'}\n",
      "{'C', 'A', 'F', 'G', 'B', 'E', 'D'}\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "filepath1 = \"Data/train.csv\"\n",
    "filepath2 = \"Data/test.csv\"\n",
    "train = pd.read_csv(filepath1)\n",
    "test = pd.read_csv(filepath2)\n",
    "\n",
    "#Wrangle data\n",
    "train = wrangle.wrangle(train)\n",
    "test = wrangle.wrangle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Ticket_Num</th>\n",
       "      <th>Cabin_Yes</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Prefix_SOP</th>\n",
       "      <th>Ticket_Prefix_SOPP</th>\n",
       "      <th>Ticket_Prefix_SOTONO2</th>\n",
       "      <th>Ticket_Prefix_SOTONOQ</th>\n",
       "      <th>Ticket_Prefix_SP</th>\n",
       "      <th>Ticket_Prefix_STONO 2</th>\n",
       "      <th>Ticket_Prefix_STONO2</th>\n",
       "      <th>Ticket_Prefix_SWPP</th>\n",
       "      <th>Ticket_Prefix_WC</th>\n",
       "      <th>Ticket_Prefix_WEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>21171.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>17599.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>3101282.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>113803.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>373450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  Ticket_Num  Cabin_Yes  \\\n",
       "0         0       3  22.0      1      0   7.2500     21171.0          0   \n",
       "1         1       1  38.0      1      0  71.2833     17599.0          1   \n",
       "2         1       3  26.0      0      0   7.9250   3101282.0          0   \n",
       "3         1       1  35.0      1      0  53.1000    113803.0          1   \n",
       "4         0       3  35.0      0      0   8.0500    373450.0          0   \n",
       "\n",
       "   Cabin_C  Cabin_A        ...          Ticket_Prefix_SOP  Ticket_Prefix_SOPP  \\\n",
       "0        0        0        ...                          0                   0   \n",
       "1        1        0        ...                          0                   0   \n",
       "2        0        0        ...                          0                   0   \n",
       "3        1        0        ...                          0                   0   \n",
       "4        0        0        ...                          0                   0   \n",
       "\n",
       "   Ticket_Prefix_SOTONO2  Ticket_Prefix_SOTONOQ  Ticket_Prefix_SP  \\\n",
       "0                      0                      0                 0   \n",
       "1                      0                      0                 0   \n",
       "2                      0                      0                 0   \n",
       "3                      0                      0                 0   \n",
       "4                      0                      0                 0   \n",
       "\n",
       "   Ticket_Prefix_STONO 2  Ticket_Prefix_STONO2  Ticket_Prefix_SWPP  \\\n",
       "0                      0                     0                   0   \n",
       "1                      0                     0                   0   \n",
       "2                      0                     1                   0   \n",
       "3                      0                     0                   0   \n",
       "4                      0                     0                   0   \n",
       "\n",
       "   Ticket_Prefix_WC  Ticket_Prefix_WEP  \n",
       "0                 0                  0  \n",
       "1                 0                  0  \n",
       "2                 0                  0  \n",
       "3                 0                  0  \n",
       "4                 0                  0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Ticket_Num</th>\n",
       "      <th>Cabin_Yes</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Prefix_SCParis</th>\n",
       "      <th>Ticket_Prefix_SOC</th>\n",
       "      <th>Ticket_Prefix_SOPP</th>\n",
       "      <th>Ticket_Prefix_SOTONO2</th>\n",
       "      <th>Ticket_Prefix_SOTONOQ</th>\n",
       "      <th>Ticket_Prefix_STONO 2</th>\n",
       "      <th>Ticket_Prefix_STONO2</th>\n",
       "      <th>Ticket_Prefix_STONOQ</th>\n",
       "      <th>Ticket_Prefix_WC</th>\n",
       "      <th>Ticket_Prefix_WEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>330911.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>363272.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>240276.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>315154.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>3101298.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Ticket_Num  Cabin_Yes  Cabin_C  \\\n",
       "0       3  34.5      0      0   7.8292    330911.0          0        0   \n",
       "1       3  47.0      1      0   7.0000    363272.0          0        0   \n",
       "2       2  62.0      0      0   9.6875    240276.0          0        0   \n",
       "3       3  27.0      0      0   8.6625    315154.0          0        0   \n",
       "4       3  22.0      1      1  12.2875   3101298.0          0        0   \n",
       "\n",
       "   Cabin_A  Cabin_F        ...          Ticket_Prefix_SCParis  \\\n",
       "0        0        0        ...                              0   \n",
       "1        0        0        ...                              0   \n",
       "2        0        0        ...                              0   \n",
       "3        0        0        ...                              0   \n",
       "4        0        0        ...                              0   \n",
       "\n",
       "   Ticket_Prefix_SOC  Ticket_Prefix_SOPP  Ticket_Prefix_SOTONO2  \\\n",
       "0                  0                   0                      0   \n",
       "1                  0                   0                      0   \n",
       "2                  0                   0                      0   \n",
       "3                  0                   0                      0   \n",
       "4                  0                   0                      0   \n",
       "\n",
       "   Ticket_Prefix_SOTONOQ  Ticket_Prefix_STONO 2  Ticket_Prefix_STONO2  \\\n",
       "0                      0                      0                     0   \n",
       "1                      0                      0                     0   \n",
       "2                      0                      0                     0   \n",
       "3                      0                      0                     0   \n",
       "4                      0                      0                     0   \n",
       "\n",
       "   Ticket_Prefix_STONOQ  Ticket_Prefix_WC  Ticket_Prefix_WEP  \n",
       "0                     0                 0                  0  \n",
       "1                     0                 0                  0  \n",
       "2                     0                 0                  0  \n",
       "3                     0                 0                  0  \n",
       "4                     0                 0                  0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Begin analysis by removing passengers with missing data\n",
    "- Uses median value data imputation strategy to fill in missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows with missing values is 891\n",
      "The number of rows without missing values is 710\n"
     ]
    }
   ],
   "source": [
    "#Create dataframe with removed rows with null values\n",
    "print(\"The number of rows with missing values is\", train.shape[0])\n",
    "train_nona = train.dropna()\n",
    "print(\"The number of rows without missing values is\", train_nona.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = train_nona.iloc[:,1:]\n",
    "y = train_nona.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imputation of missing values for training data\n",
    "imp_median = sklearn.preprocessing.Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "X_median = imp_median.fit_transform(train.iloc[:,1:])\n",
    "\n",
    "#Retrieve full y column for model fitting\n",
    "y_full = train.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Independent observations\n",
    "- Independent errors\n",
    "- Linear relationship between log-odds of the dependent variable and model features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = sklearn.linear_model.LogisticRegression()\n",
    "log = log.fit(X,y)\n",
    "log_scores = sklearn.model_selection.cross_val_score(log, X, y, cv=10, scoring='accuracy')\n",
    "train_log_acc = log.score(X,y)\n",
    "cv_log_acc = log_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_cv = sklearn.linear_model.LogisticRegressionCV(cv = 10, solver =\"liblinear\", penalty = \"l1\", random_state = 100)\n",
    "log_cv = log_cv.fit(X, y)\n",
    "#C_ stores the inverse of the regularization parameter\n",
    "C = float((log_cv.C_)**-1)\n",
    "\n",
    "#Got this warning: Warning: The least populated class in y has only 289 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=710."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Subsampling and fitting a L1-penalized logsitic regression model using lambda (C) from previous CV model\n",
    "# Assessing correspondence between features selected from CV L1 model and percentage of time that feature is selected when repeatedly sampling with same C penalty\n",
    "log_rand = sklearn.linear_model.RandomizedLogisticRegression(C = C, n_resampling=200, random_state = 100)\n",
    "log_rand = log_rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>LogReg</th>\n",
       "      <th>L1Penalty</th>\n",
       "      <th>RandomScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>[-0.000683696137035]</td>\n",
       "      <td>[-0.752084771567]</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>[-0.00668949649784]</td>\n",
       "      <td>[-0.0316193671789]</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>[-0.000101374230163]</td>\n",
       "      <td>[-0.282473243547]</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parch</td>\n",
       "      <td>[1.29228868844e-05]</td>\n",
       "      <td>[-0.0399485205897]</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fare</td>\n",
       "      <td>[0.00761774935147]</td>\n",
       "      <td>[0.00357124060763]</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ticket_Num</td>\n",
       "      <td>[-4.89524533038e-07]</td>\n",
       "      <td>[1.33760647899e-07]</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Yes</td>\n",
       "      <td>[0.00011009679806]</td>\n",
       "      <td>[0.640287078821]</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_C</td>\n",
       "      <td>[1.08637345725e-05]</td>\n",
       "      <td>[-0.33203522908]</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_A</td>\n",
       "      <td>[3.7557589563e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_F</td>\n",
       "      <td>[6.72786057955e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_G</td>\n",
       "      <td>[-4.75243560017e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_T</td>\n",
       "      <td>[-1.8365566451e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cabin_E</td>\n",
       "      <td>[2.621623929e-05]</td>\n",
       "      <td>[0.280096501905]</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cabin_B</td>\n",
       "      <td>[3.71745538611e-05]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cabin_D</td>\n",
       "      <td>[2.68766142511e-05]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>female</td>\n",
       "      <td>[0.000264745518938]</td>\n",
       "      <td>[2.49023794221]</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>male</td>\n",
       "      <td>[-0.000432081005335]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>[4.39772384599e-05]</td>\n",
       "      <td>[0.332393548351]</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>[-1.85505375025e-05]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>[-0.000196456927872]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ticket_Prefix_</td>\n",
       "      <td>[-0.000145541459383]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ticket_Prefix_A4</td>\n",
       "      <td>[-9.28681517737e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ticket_Prefix_A5</td>\n",
       "      <td>[-2.5923623938e-05]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ticket_Prefix_AS</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ticket_Prefix_C</td>\n",
       "      <td>[-1.79158313391e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ticket_Prefix_CA</td>\n",
       "      <td>[-9.5190153916e-06]</td>\n",
       "      <td>[0.0915426211386]</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ticket_Prefix_CASOTON</td>\n",
       "      <td>[-1.85010670279e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Ticket_Prefix_FC</td>\n",
       "      <td>[-1.92896145733e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Ticket_Prefix_FCC</td>\n",
       "      <td>[5.6621530534e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ticket_Prefix_Fa</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ticket_Prefix_LINE</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Ticket_Prefix_PC</td>\n",
       "      <td>[2.92898127678e-05]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ticket_Prefix_PP</td>\n",
       "      <td>[1.86797628281e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ticket_Prefix_PPP</td>\n",
       "      <td>[-1.9430886457e-08]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ticket_Prefix_SC</td>\n",
       "      <td>[1.87554744216e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ticket_Prefix_SCA4</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ticket_Prefix_SCAH</td>\n",
       "      <td>[7.70140239993e-09]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ticket_Prefix_SCAH Basle</td>\n",
       "      <td>[1.87797363152e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ticket_Prefix_SCOW</td>\n",
       "      <td>[-1.86405310419e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Ticket_Prefix_SCPARIS</td>\n",
       "      <td>[-1.98225856317e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ticket_Prefix_SCParis</td>\n",
       "      <td>[-1.43452732335e-07]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ticket_Prefix_SOC</td>\n",
       "      <td>[-7.9782830333e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ticket_Prefix_SOP</td>\n",
       "      <td>[-1.84631995928e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ticket_Prefix_SOPP</td>\n",
       "      <td>[-3.71656526937e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ticket_Prefix_SOTONO2</td>\n",
       "      <td>[-1.21317975101e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Ticket_Prefix_SOTONOQ</td>\n",
       "      <td>[-2.82540501499e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Ticket_Prefix_SP</td>\n",
       "      <td>[-1.8702343337e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Ticket_Prefix_STONO 2</td>\n",
       "      <td>[1.14854903512e-05]</td>\n",
       "      <td>[0.275137415332]</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Ticket_Prefix_STONO2</td>\n",
       "      <td>[7.59324878352e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Ticket_Prefix_SWPP</td>\n",
       "      <td>[3.80353507015e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Ticket_Prefix_WC</td>\n",
       "      <td>[-9.43552887797e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Ticket_Prefix_WEP</td>\n",
       "      <td>[-2.0626484723e-06]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature                LogReg            L1Penalty  \\\n",
       "0                     Pclass  [-0.000683696137035]    [-0.752084771567]   \n",
       "1                        Age   [-0.00668949649784]   [-0.0316193671789]   \n",
       "2                      SibSp  [-0.000101374230163]    [-0.282473243547]   \n",
       "3                      Parch   [1.29228868844e-05]   [-0.0399485205897]   \n",
       "4                       Fare    [0.00761774935147]   [0.00357124060763]   \n",
       "5                 Ticket_Num  [-4.89524533038e-07]  [1.33760647899e-07]   \n",
       "6                  Cabin_Yes    [0.00011009679806]     [0.640287078821]   \n",
       "7                    Cabin_C   [1.08637345725e-05]     [-0.33203522908]   \n",
       "8                    Cabin_A    [3.7557589563e-06]                [0.0]   \n",
       "9                    Cabin_F   [6.72786057955e-06]                [0.0]   \n",
       "10                   Cabin_G  [-4.75243560017e-06]                [0.0]   \n",
       "11                   Cabin_T   [-1.8365566451e-06]                [0.0]   \n",
       "12                   Cabin_E     [2.621623929e-05]     [0.280096501905]   \n",
       "13                   Cabin_B   [3.71745538611e-05]                [0.0]   \n",
       "14                   Cabin_D   [2.68766142511e-05]                [0.0]   \n",
       "15                    female   [0.000264745518938]      [2.49023794221]   \n",
       "16                      male  [-0.000432081005335]                [0.0]   \n",
       "17                Embarked_C   [4.39772384599e-05]     [0.332393548351]   \n",
       "18                Embarked_Q  [-1.85505375025e-05]                [0.0]   \n",
       "19                Embarked_S  [-0.000196456927872]                [0.0]   \n",
       "20            Ticket_Prefix_  [-0.000145541459383]                [0.0]   \n",
       "21          Ticket_Prefix_A4  [-9.28681517737e-06]                [0.0]   \n",
       "22          Ticket_Prefix_A5   [-2.5923623938e-05]                [0.0]   \n",
       "23          Ticket_Prefix_AS                 [0.0]                [0.0]   \n",
       "24           Ticket_Prefix_C  [-1.79158313391e-06]                [0.0]   \n",
       "25          Ticket_Prefix_CA   [-9.5190153916e-06]    [0.0915426211386]   \n",
       "26     Ticket_Prefix_CASOTON  [-1.85010670279e-06]                [0.0]   \n",
       "27          Ticket_Prefix_FC  [-1.92896145733e-06]                [0.0]   \n",
       "28         Ticket_Prefix_FCC    [5.6621530534e-06]                [0.0]   \n",
       "29          Ticket_Prefix_Fa                 [0.0]                [0.0]   \n",
       "30        Ticket_Prefix_LINE                 [0.0]                [0.0]   \n",
       "31          Ticket_Prefix_PC   [2.92898127678e-05]                [0.0]   \n",
       "32          Ticket_Prefix_PP   [1.86797628281e-06]                [0.0]   \n",
       "33         Ticket_Prefix_PPP   [-1.9430886457e-08]                [0.0]   \n",
       "34          Ticket_Prefix_SC   [1.87554744216e-06]                [0.0]   \n",
       "35        Ticket_Prefix_SCA4                 [0.0]                [0.0]   \n",
       "36        Ticket_Prefix_SCAH   [7.70140239993e-09]                [0.0]   \n",
       "37  Ticket_Prefix_SCAH Basle   [1.87797363152e-06]                [0.0]   \n",
       "38        Ticket_Prefix_SCOW  [-1.86405310419e-06]                [0.0]   \n",
       "39     Ticket_Prefix_SCPARIS  [-1.98225856317e-06]                [0.0]   \n",
       "40     Ticket_Prefix_SCParis  [-1.43452732335e-07]                [0.0]   \n",
       "41         Ticket_Prefix_SOC   [-7.9782830333e-06]                [0.0]   \n",
       "42         Ticket_Prefix_SOP  [-1.84631995928e-06]                [0.0]   \n",
       "43        Ticket_Prefix_SOPP  [-3.71656526937e-06]                [0.0]   \n",
       "44     Ticket_Prefix_SOTONO2  [-1.21317975101e-06]                [0.0]   \n",
       "45     Ticket_Prefix_SOTONOQ  [-2.82540501499e-06]                [0.0]   \n",
       "46          Ticket_Prefix_SP   [-1.8702343337e-06]                [0.0]   \n",
       "47     Ticket_Prefix_STONO 2   [1.14854903512e-05]     [0.275137415332]   \n",
       "48      Ticket_Prefix_STONO2   [7.59324878352e-06]                [0.0]   \n",
       "49        Ticket_Prefix_SWPP   [3.80353507015e-06]                [0.0]   \n",
       "50          Ticket_Prefix_WC  [-9.43552887797e-06]                [0.0]   \n",
       "51         Ticket_Prefix_WEP   [-2.0626484723e-06]                [0.0]   \n",
       "\n",
       "    RandomScore  \n",
       "0         1.000  \n",
       "1         1.000  \n",
       "2         0.610  \n",
       "3         0.085  \n",
       "4         0.375  \n",
       "5         0.005  \n",
       "6         0.670  \n",
       "7         0.180  \n",
       "8         0.220  \n",
       "9         0.410  \n",
       "10        0.350  \n",
       "11        0.220  \n",
       "12        0.720  \n",
       "13        0.175  \n",
       "14        0.235  \n",
       "15        0.765  \n",
       "16        0.715  \n",
       "17        0.610  \n",
       "18        0.135  \n",
       "19        0.265  \n",
       "20        0.070  \n",
       "21        0.000  \n",
       "22        0.100  \n",
       "23        0.000  \n",
       "24        0.270  \n",
       "25        0.145  \n",
       "26        0.000  \n",
       "27        0.335  \n",
       "28        0.235  \n",
       "29        0.000  \n",
       "30        0.000  \n",
       "31        0.100  \n",
       "32        0.065  \n",
       "33        0.000  \n",
       "34        0.000  \n",
       "35        0.000  \n",
       "36        0.000  \n",
       "37        0.000  \n",
       "38        0.000  \n",
       "39        0.000  \n",
       "40        0.000  \n",
       "41        0.165  \n",
       "42        0.000  \n",
       "43        0.475  \n",
       "44        0.000  \n",
       "45        0.025  \n",
       "46        0.000  \n",
       "47        0.795  \n",
       "48        0.030  \n",
       "49        0.770  \n",
       "50        0.465  \n",
       "51        0.130  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Table of feature selection diagnostics\n",
    "pd.DataFrame(list(zip(X.columns, \n",
    "                      np.transpose(log.coef_),\n",
    "                      np.transpose(log_cv.coef_),\n",
    "                      np.transpose(log_rand.scores_))),columns=[\"Feature\",\"LogReg\", \"L1Penalty\", \"RandomScore\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Retrieve mean CV prediction accuracy using L1 penalty logistic regression model\n",
    "log_l1 = sklearn.linear_model.LogisticRegression(penalty = 'l1', C = C**-1)\n",
    "log_l1_scores = sklearn.model_selection.cross_val_score(log_l1, X, y, cv=10, scoring='accuracy')\n",
    "log_l1 = log_l1.fit(X,y)\n",
    "train_log_l1_acc = log_l1.score(X,y)\n",
    "cv_log_l1_acc = log_l1_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model assumptions\n",
    "\n",
    "- Nonparametric statistical model\n",
    "- Data is in metric space\n",
    "- Minkowski distance metric (generalized Euclidean space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of 50 integers for K\n",
    "neighbors = list(range(1,50))\n",
    "\n",
    "#Cross-validation scores for each K \n",
    "knn_cv_scores = []\n",
    "\n",
    "# 10-Fold cross validation and store average CV prediction accuracy score\n",
    "for K in neighbors:\n",
    "    knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors= K)\n",
    "    scores = sklearn.model_selection.cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    knn_cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFlCAYAAADyLnFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA91ZzrJCFzVpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb506438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neighbors,knn_cv_scores)\n",
    "plt.title(\"KNN Mean Cross-validated Prediction Accuracy Based on K\")\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Prediction Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We oberserve that 5 is the optimal K\n",
    "#Conduct ten-fold cross validation\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn_scores = sklearn.model_selection.cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "knn = knn.fit(X,y)\n",
    "train_knn_acc = knn.score(X,y)\n",
    "cv_knn_acc = knn_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation and Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ten-fold cross-validation with \n",
    "lsvc = sklearn.svm.LinearSVC(penalty='l2', random_state = 100)\n",
    "lsvc_scores = sklearn.model_selection.cross_val_score(lsvc, X, y, cv=10, scoring='accuracy')\n",
    "lsvc = lsvc.fit(X,y)\n",
    "train_lsvc_acc = lsvc.score(X,y)\n",
    "cv_lsvc_acc = lsvc_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ten fold cross validation with\n",
    "svcrbf = sklearn.svm.SVC(kernel='rbf')\n",
    "svcrbf_scores = sklearn.model_selection.cross_val_score(svcrbf, X, y, cv=10, scoring='accuracy')\n",
    "svcrbf = svcrbf.fit(X,y)\n",
    "train_svcrbf_acc = svcrbf.score(X,y)\n",
    "cv_svcrbf_acc = svcrbf_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Assumptions\n",
    "\n",
    "- Normally distributed features\n",
    "- Features are independent for a given class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation and Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prior = np.array([0.5,0.5])\n",
    "gnb = sklearn.naive_bayes.GaussianNB(priors = prior) #Prior asserts 50-50 chance of survival\n",
    "gnb_scores = sklearn.model_selection.cross_val_score(gnb, X, y, cv=10, scoring='accuracy')\n",
    "gnb = gnb.fit(X,y)\n",
    "train_gnb_acc = gnb.score(X,y)\n",
    "cv_gnb_acc = gnb_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=100, max_features=\"sqrt\", random_state = 100)\n",
    "rf_scores = sklearn.model_selection.cross_val_score(rf, X, y, cv=10, scoring='accuracy')\n",
    "rf = rf.fit(X,y)\n",
    "train_rf_acc = rf.score(X,y)\n",
    "cv_rf_acc = rf_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extremely Randomized Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ert = sklearn.ensemble.ExtraTreesClassifier(n_estimators=100, max_features=\"sqrt\", random_state = 100)\n",
    "ert_scores = sklearn.model_selection.cross_val_score(ert, X, y, cv=10, scoring='accuracy')\n",
    "ert = ert.fit(X,y)\n",
    "train_ert_acc = ert.score(X,y)\n",
    "cv_ert_acc = ert_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ab = sklearn.ensemble.AdaBoostClassifier(n_estimators=100, random_state = 100)\n",
    "ab_scores = sklearn.model_selection.cross_val_score(ab, X, y, cv=10, scoring='accuracy')\n",
    "ab = ab.fit(X,y)\n",
    "train_ab_acc = ab.score(X,y)\n",
    "cv_ab_acc = ab_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc = sklearn.ensemble.GradientBoostingClassifier(n_estimators=100, random_state = 100)\n",
    "gbc_scores = sklearn.model_selection.cross_val_score(gbc, X, y, cv=10, scoring='accuracy')\n",
    "gbc = gbc.fit(X,y)\n",
    "train_gbc_acc = gbc.score(X,y)\n",
    "cv_gbc_acc = gbc_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Accuracy Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Mean CV Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.697183</td>\n",
       "      <td>0.686019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression L1</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.784558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.686021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Support Vector</td>\n",
       "      <td>0.567606</td>\n",
       "      <td>0.515637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RBF Support Vector</td>\n",
       "      <td>0.961972</td>\n",
       "      <td>0.649382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.660563</td>\n",
       "      <td>0.663485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Extremely Randomized Trees</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.801539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.802948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.912676</td>\n",
       "      <td>0.831078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Train Accuracy  Mean CV Accuracy\n",
       "0           Logistic Regression        0.697183          0.686019\n",
       "1        Logistic Regression L1        0.797183          0.784558\n",
       "2                           KNN        0.774648          0.686021\n",
       "3         Linear Support Vector        0.567606          0.515637\n",
       "4            RBF Support Vector        0.961972          0.649382\n",
       "5          Gaussian Naive Bayes        0.660563          0.663485\n",
       "6                 Random Forest        1.000000          0.821239\n",
       "7    Extremely Randomized Trees        1.000000          0.801539\n",
       "8                      Adaboost        0.873239          0.802948\n",
       "9  Gradient Boosting Classifier        0.912676          0.831078"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_items([('Model', [\"Logistic Regression\",\n",
    "                                    \"Logistic Regression L1\",\n",
    "                                    \"KNN\",\n",
    "                                    \"Linear Support Vector\",\n",
    "                                    \"RBF Support Vector\",\n",
    "                                    \"Gaussian Naive Bayes\",\n",
    "                                    \"Random Forest\",\n",
    "                                    \"Extremely Randomized Trees\",\n",
    "                                    \"Adaboost\",\n",
    "                                    \"Gradient Boosting Classifier\"]),\n",
    "                          ('Train Accuracy', [train_log_acc,\n",
    "                                          train_log_l1_acc,\n",
    "                                          train_knn_acc,\n",
    "                                          train_lsvc_acc,\n",
    "                                          train_svcrbf_acc,\n",
    "                                          train_gnb_acc,\n",
    "                                          train_rf_acc,\n",
    "                                          train_ert_acc,\n",
    "                                          train_ab_acc,\n",
    "                                          train_gbc_acc]),\n",
    "                         ('Mean CV Accuracy', [cv_log_acc,\n",
    "                                          cv_log_l1_acc,\n",
    "                                          cv_knn_acc,\n",
    "                                          cv_lsvc_acc,\n",
    "                                          cv_svcrbf_acc,\n",
    "                                          cv_gnb_acc,\n",
    "                                          cv_rf_acc,\n",
    "                                          cv_ert_acc,\n",
    "                                          cv_ab_acc,\n",
    "                                          cv_gbc_acc])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with Median-Value Imputed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imputed data using median strategy will be used.\n",
    "- All models with predictive accuracy higher than 75% will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic regression with L1 regularizer\n",
    "log_l1_median_scores = sklearn.model_selection.cross_val_score(log_l1, X_median, y_full, cv=10, scoring='accuracy')\n",
    "cv_log_l1_median_acc = log_l1_median_scores.mean()\n",
    "\n",
    "#Random forest\n",
    "rf_median_scores = sklearn.model_selection.cross_val_score(rf, X_median, y_full, cv=10, scoring='accuracy')\n",
    "cv_rf_median_acc = rf_median_scores.mean()\n",
    "\n",
    "#Extremely randomized trees\n",
    "ert_median_scores = sklearn.model_selection.cross_val_score(ert, X_median, y_full, cv=10, scoring='accuracy')\n",
    "cv_ert_median_acc = ert_median_scores.mean()\n",
    "\n",
    "#AdaBoost\n",
    "ab_median_scores = sklearn.model_selection.cross_val_score(ab, X_median, y_full, cv=10, scoring='accuracy')\n",
    "cv_ab_median_acc = ab_median_scores.mean()\n",
    "\n",
    "#Gradient Boosting Classification\n",
    "gbc_median_scores = sklearn.model_selection.cross_val_score(gbc, X_median, y_full, cv=10, scoring='accuracy')\n",
    "cv_gbc_median_acc = gbc_median_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean CV Accuracy</th>\n",
       "      <th>Median Value Imputation Mean CV Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression L1</td>\n",
       "      <td>0.784558</td>\n",
       "      <td>0.792405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.821239</td>\n",
       "      <td>0.838448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extremely Randomized Trees</td>\n",
       "      <td>0.801539</td>\n",
       "      <td>0.811481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.802948</td>\n",
       "      <td>0.821619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.831078</td>\n",
       "      <td>0.839635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Mean CV Accuracy  \\\n",
       "0        Logistic Regression L1          0.784558   \n",
       "1                 Random Forest          0.821239   \n",
       "2    Extremely Randomized Trees          0.801539   \n",
       "3                      Adaboost          0.802948   \n",
       "4  Gradient Boosting Classifier          0.831078   \n",
       "\n",
       "   Median Value Imputation Mean CV Accuracy  \n",
       "0                                  0.792405  \n",
       "1                                  0.838448  \n",
       "2                                  0.811481  \n",
       "3                                  0.821619  \n",
       "4                                  0.839635  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_items([('Model', [\"Logistic Regression L1\",\n",
    "                                    \"Random Forest\",\n",
    "                                    \"Extremely Randomized Trees\",\n",
    "                                    \"Adaboost\",\n",
    "                                    \"Gradient Boosting Classifier\"]),\n",
    "                         ('Mean CV Accuracy', [cv_log_l1_acc,\n",
    "                                               cv_rf_acc,\n",
    "                                               cv_ert_acc,\n",
    "                                               cv_ab_acc,\n",
    "                                               cv_gbc_acc]),\n",
    "                        ('Median Value Imputation Mean CV Accuracy', [cv_log_l1_median_acc,\n",
    "                                                                      cv_rf_median_acc,\n",
    "                                                                      cv_ert_median_acc,\n",
    "                                                                      cv_ab_median_acc,\n",
    "                                                                      cv_gbc_median_acc\n",
    "                                                                     ])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given the table above, we can demonstrate that cross validated prediction accuracy improves using a median value imputation strategy\n",
    "- This may justify using median value imputation for future test data\n",
    "- We also note the random forest model is nearly identical in predictive accuracy to the gradient boosting classifier model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The gradient boosting classifier model will be used to make test data predictions because it has the highest prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 52 and input n_features is 47 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-6df286905a7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m#Predict using test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1533\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \"\"\"\n\u001b[0;32m-> 1535\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m         \u001b[0mdecisions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_score_to_decision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecisions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \"\"\"\n\u001b[1;32m   1493\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[1;31m# for use in inner loop, not raveling the output in single-class case,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[1;31m# not doing input validation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0mpredict_stages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_init_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[1;34m\"\"\"Check input and compute prediction of ``init``. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    374\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 52 and input n_features is 47 "
     ]
    }
   ],
   "source": [
    "### NEED TO MAKE SURE TEST DATA FEATURES ALIGN WITH TRAINING FEATURES\n",
    "### MAYBE KEEP PASSENGER ID\n",
    "\n",
    "#Impute test data\n",
    "test = imp_median.fit_transform(test)\n",
    "\n",
    "#Predict using test data\n",
    "test_prediction = gbc.predict(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
